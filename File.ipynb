{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35799d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "import os, re\n",
    "import sys\n",
    "import glob\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse\n",
    "from subprocess import run\n",
    "\n",
    "from numexpr import evaluate as ne_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a428b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger(level=logging.INFO, name=__name__):\n",
    "    logger = logging.getLogger(__class__.__qualname__) or logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    handler = logging.FileHandler('log_file.log')\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s : %(name)s  : %(funcName)s : %(levelname)s : %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2358a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = os.path.abspath(r\"../data/10X/cleaned/1998/QTR2/\") # on home\n",
    "PATH = os.path.abspath(r\"C:\\Users\\wonhyeong\\workings\\data\\10X\\cleaned\") # on office\n",
    "# PATH = os.path.abspath(r\"/Users/wonhyeong/workings/data/10X/cleaned\")  # on mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b7aaf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spider:\n",
    "    # import modules\n",
    "    import os\n",
    "    import datetime as dt\n",
    "    from pathlib import Path\n",
    "    from dateutil.parser import parse\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from numexpr import evaluate as ne_eval\n",
    "\n",
    "    def __init__(self, data_path, index_path = 'index.pkl'):\n",
    "        # self.index.index = ['acc']\n",
    "        # self.index.cols = ['cik', 'date', 'type', 'name', 'ticker', 'exchange', 'path']\n",
    "        self.dir = Path(data_path)\n",
    "        self.index_path = self.dir / index_path\n",
    "        self.index = pd.read_pickle(self.index_path) if (self.index_path).exists() else None\n",
    "        self.columns = ['acc', 'cik', 'date', 'type', 'name', 'ticker', 'exchange', 'path']\n",
    "        return\n",
    "\n",
    "    def search(self, keywords=None, output='acc'):\n",
    "        \"\"\"\"\"\"\n",
    "        # assert is_string keywords.isstr < 2, \"list input is not supported currently\"\n",
    "        assert output in self.columns, f\"output must be one of {self.columns}\"\n",
    "        if not keywords:\n",
    "            return os.listdir(self.dir)\n",
    "        # search by keyword\n",
    "        key, modifier = self._search_preprocess(str(keywords[0]))\n",
    "        assert modifier or key, \"There's something wrong with your input\"\n",
    "        matrix = []\n",
    "        if modifier:\n",
    "            matrix.append([self._get_from_modifier(mod, value)\n",
    "                          for mod, value in modifier.items()])\n",
    "        if key:\n",
    "            matrix.append([self._get_from_key(key, value)\n",
    "                          for key, value in key.items()])\n",
    "        idx = np.multiply.reduce(matrix)\n",
    "        # to boolean array\n",
    "        idx = np.array([True if i else False for i in idx[0]])\n",
    "        result = getattr(self.index, output)[idx]\n",
    "        return result\n",
    "\n",
    "    def company(self, after=0, before=99999999, std_freq=None, get_period=True, get_count=False):\n",
    "        \"\"\"\n",
    "        get company list\n",
    "        :param after: after this date\n",
    "        :param before: before this date\n",
    "        :param std_freq: standard frequency\n",
    "        :param get_period: get period in tuple\n",
    "        :param get_count: get count in tuple\n",
    "        :return: list(tuple or str)\n",
    "        \"\"\"\n",
    "        after, before = self._date_preprocess(after, before)\n",
    "        co = self.search(f'after:{after} before:{before}', output='cik').value_counts()\n",
    "        assert co is not None, \"There's no company matching in query\"\n",
    "\n",
    "        zipped = [co.index]\n",
    "        # get count of filings\n",
    "        if get_count:\n",
    "            zipped.append(co.values)\n",
    "        # get period\n",
    "        if get_period:\n",
    "            zipped.append(list(np.full(len(co), '-'.join([str(after), str(before)]))))\n",
    "        if len(zipped) == 1:\n",
    "            return zipped[0]\n",
    "            \n",
    "        return list(zip(zipped))\n",
    "\n",
    "    def _search_preprocess(self, keyword):\n",
    "        # params : string for search\n",
    "        # return : list of keywords + tags\n",
    "        key_tags = ['cik', 'date', 'name', 'symbol', 'acc', 'form']\n",
    "        modifier_tags = ['after', 'before', 'year', 'qtr']\n",
    "        keyword_list = keyword.split(' ')\n",
    "        # unknown 인식 및 처리 과정 필요\n",
    "        unknown = list(filter(lambda x: ':' not in x, keyword_list))\n",
    "        tag = list(filter(lambda x: ':' in x, keyword_list))\n",
    "        tag = dict(tuple(x.split(':')) for x in tag) if tag else {}\n",
    "        key = {k: v for k, v in tag.items() if k in key_tags}\n",
    "        modifier = {k: v for k, v in tag.items() if k in modifier_tags}\n",
    "        # 현재 dateparser 적용 안되는 오류\n",
    "        for k, val in modifier.items():\n",
    "            val = self._date_preprocess(val)\n",
    "        modifier = {k: v for k, v in modifier.items() if v}\n",
    "        return key, modifier\n",
    "\n",
    "    def _date_preprocess(self, date):\n",
    "        if len(date) == 4:\n",
    "            if date.startswith(('19', '20')):\n",
    "                # 연도만 입력된 경우\n",
    "                return date+'0101'\n",
    "            if date <= '1231':\n",
    "                # 월일만 입력된 경우, 분기조건 수정 필요\n",
    "                year = str(dt.now().year)\n",
    "                return year + date\n",
    "        # try 내에서 return 사용 가능?\n",
    "        try:\n",
    "            result = parse(date).strftime('%Y%m%d')\n",
    "        except:\n",
    "            return None\n",
    "        return result\n",
    "\n",
    "    def _get_from_key(self, key, value):\n",
    "        col = self.columns[key]\n",
    "        idx = ne_eval(f'(col == {value})')\n",
    "        return idx\n",
    "\n",
    "    def _get_from_modifier(self, modifier, value):\n",
    "        date = self.columns[\"date\"]\n",
    "        value = str(value)\n",
    "        after = \"10000000\"\n",
    "        before = \"99999999\"\n",
    "        if modifier == 'after':\n",
    "            after = value\n",
    "        elif modifier == 'before':\n",
    "            before = value\n",
    "        elif modifier == 'year':\n",
    "            after = value[:4] + '0101'\n",
    "            before = value[:4] + '1231'\n",
    "        elif modifier == 'qtr':\n",
    "            after = value\n",
    "            before = value[:4] + str(int(value[4:6])+3) + value[6:]\n",
    "        idx = ne_eval(f'({int(after)} < date) & (date < {int(before)})')\n",
    "        return idx\n",
    "\n",
    "    def _date_to_path(self, date):\n",
    "        date = str(date)\n",
    "        year = date[:4]\n",
    "        # month to quarter\n",
    "        month = int(date[4:6])\n",
    "        quarter = (month-1) // 3 + 1\n",
    "        quarter = ''.join(['QTR', str(quarter)])\n",
    "        path = self.dir / year / quarter\n",
    "        return path\n",
    "        \n",
    "    def _get_index(self):\n",
    "        \"\"\" 전부 수정 필요 \"\"\"\n",
    "        f = open(self.dir / 'log.txt', 'r')\n",
    "        log = [l.strip() for l in f.readlines()]\n",
    "        log = (l for l in log if l)\n",
    "\n",
    "        df = pd.DataFrame(log, columns=['path'])\n",
    "        df['path'] = df['path'].apply(lambda x: x.replace(str(self.dir), ''))\n",
    "        df['path'] = df['path'].apply(lambda x: x[1:])\n",
    "\n",
    "        df = df[df['path'].contains(os.sep)]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df['acc'] = df['path'].apply(lambda x: x.split('_')[5].split('.')[0])\n",
    "        df.set_index('acc', inplace=True)\n",
    "\n",
    "        self.index = df\n",
    "        return \n",
    "\n",
    "    def _get_dir_index_faster(self):\n",
    "        \"\"\"\n",
    "        lot more faster than os.walk\n",
    "        \"\"\"\n",
    "        # check path is pathlib.Path\n",
    "        index_path = Path(os.getcwd()) / 'index.txt'\n",
    "        options = f'/MIR /FP /NC /NS /NDL /NJH /NJS /LOG:index.txt /L'\n",
    "        cmd = f'robocopy {str(self.path)} NULL {options}'\n",
    "        # why this is too slow????\n",
    "        run(['powershell', '-c', cmd])\n",
    "\n",
    "        f = open(index_path, 'r')\n",
    "        index = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        return index\n",
    "\n",
    "    def _get_dir_tree(self):\n",
    "        tree = pd.DataFrame(columns=[\"name\", \"path\", \"depth\", \"files\"])\n",
    "        for root, dirs, files in os.walk(self.dir):\n",
    "            name = os.path.basename(root)\n",
    "            this = root.replace(self.dir, \"\")\n",
    "            depth = int(this.count(os.sep))\n",
    "            count = len(files)\n",
    "            # 숨김 폴더거나, 그 자식 노드일 경우 스킵\n",
    "            if any(f.startswith(\".\") for f in this.split(os.sep)):\n",
    "                print(\"skip:\", this)\n",
    "                continue\n",
    "            tree.loc[len(tree)] = [name, this, depth, count]\n",
    "        return tree\n",
    "    \n",
    "    def show_tree(self):\n",
    "        result = ''\n",
    "        for row in self.tree.itertuples():\n",
    "            list = ['\\t'*row.depth, row.name, f\"\\tfiles: {row.count}\\n\"]\n",
    "            result.append(''.join(list))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39605323",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "list input is not supported currently",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\내 드라이브\\workspace\\jpynb\\edgar\\File.ipynb 셀 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m files \u001b[39m=\u001b[39m spider(PATH)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m files\u001b[39m.\u001b[39;49msearch(\u001b[39m'\u001b[39;49m\u001b[39mcik:0001337930\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mg:\\내 드라이브\\workspace\\jpynb\\edgar\\File.ipynb 셀 5\u001b[0m in \u001b[0;36mspider.search\u001b[1;34m(self, keywords, output)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch\u001b[39m(\u001b[39mself\u001b[39m, keywords\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(keywords) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlist input is not supported currently\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39massert\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput must be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m keywords:\n",
      "\u001b[1;31mAssertionError\u001b[0m: list input is not supported currently"
     ]
    }
   ],
   "source": [
    "files = spider(PATH)\n",
    "files.search('cik:0001337930')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5fa07125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(dir):\n",
    "    f = open(dir / 'log.txt', 'r')\n",
    "    log = [l.strip() for l in f.readlines()]\n",
    "    log = (l for l in log if l)\n",
    "\n",
    "    df = pd.DataFrame(log, columns=['path'])\n",
    "    df['path'] = df['path'].apply(lambda x: x.replace(str(dir), ''))\n",
    "    df['path'] = df['path'].apply(lambda x: x[1:])\n",
    "\n",
    "    df = df[df['path'].str.contains(os.sep, regex=False)]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df['acc'] = df['path'].apply(lambda x: x.split('_')[5].split('.')[0])\n",
    "    df.set_index('acc', inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_summary(dir):\n",
    "    return pd.read_csv(dir / 'summaries.csv')[['CIK', 'FILING_DATE', 'ACC_NUM', 'FORM_TYPE', 'CoName']]\n",
    "\n",
    "def get_ticker(dir):\n",
    "    ticker = pd.read_csv(dir / 'cik.csv')\n",
    "    ticker.drop(ticker.columns[0], axis=1, inplace=True)\n",
    "    # limit exchange to NYSE or NASDAQ\n",
    "    # due to duplicated cik are common in OTC, we need to limit exchange first\n",
    "    ticker.drop(ticker.index[(ticker['exchange'] != 'NYSE') & (\n",
    "        ticker['exchange'] != 'Nasdaq')], inplace=True)\n",
    "    # drop all duplicates\n",
    "    ticker.drop_duplicates(subset='cik', keep='first', inplace=True)\n",
    "    ticker.drop_duplicates(subset='name', keep='first', inplace=True)\n",
    "    ticker.drop_duplicates(subset='ticker', keep='first', inplace=True)\n",
    "    # column cik to index\n",
    "    ticker.set_index('cik', inplace=True)\n",
    "    return ticker\n",
    "\n",
    "def findticker(cik):\n",
    "    try:\n",
    "        result = ticker.at[cik, 'ticker']\n",
    "    except:\n",
    "        return\n",
    "    return result\n",
    "\n",
    "def findexchange(cik):\n",
    "    try:\n",
    "        result = ticker.at[cik, 'exchange']\n",
    "    except:\n",
    "        return\n",
    "    return result\n",
    "\n",
    "dir = Path(PATH)\n",
    "index = get_index(dir)\n",
    "summary = get_summary(dir)\n",
    "ticker = get_ticker(dir)\n",
    "\n",
    "summary['TICKER'] = summary['CIK'].map(findticker)\n",
    "summary['EXCHANGE'] = summary['CIK'].map(findexchange)\n",
    "\n",
    "\n",
    "summary['path'] = summary['FILING_DATE'].apply(str) + '_' + summary['FORM_TYPE'].apply(str) + '_' + 'edgar_data' + '_' + summary['CIK'].apply(str) + '_' + summary['ACC_NUM'].apply(str)+'.txt'\n",
    "# change column name\n",
    "\n",
    "summary.rename(columns={'FILING_DATE': 'date', 'FORM_TYPE': 'type', 'CoName': 'name', 'CIK': 'cik', 'TICKER': 'ticker', 'EXCHANGE':'exchange'}, inplace=True)\n",
    "summary.rename(columns={'ACC_NUM': 'acc'}, inplace=True)\n",
    "\n",
    "summary.set_index('acc', inplace=True)\n",
    "summary.to_pickle(dir / 'summary.pkl')\n",
    "a = pd.read_pickle(dir / 'summary.pkl')\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5d32f057a3c8bd6a68a4140140c1c01731d179f143636ed2ae590c641a050cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
