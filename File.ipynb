{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35799d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import sys\n",
    "import glob\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numexpr as ne\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a428b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger(level=logging.INFO, name=__name__):\n",
    "    logger = logging.getLogger(__class__.__qualname__) or logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    handler = logging.FileHandler('log_file.log')\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s : %(name)s  : %(funcName)s : %(levelname)s : %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2358a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = os.path.abspath(r\"../data/10X/cleaned/1998/QTR2/\") # on home\n",
    "# PATH = os.path.abspath(r\"C:\\Users\\wonhyeong\\workings\\data\\10X\\cleaned\") # on office\n",
    "PATH = os.path.abspath(r\"/Users/wonhyeong/workings/data/10X/cleaned\")  # on mac\n",
    "dict_dir = \"data/summaries.csv\"\n",
    "summaries = pd.read_csv(dict_dir)[['CIK', 'FILING_DATE', 'ACC_NUM', 'FORM_TYPE', 'CoName']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "276c4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = r'/Volumes/GoogleDrive/내 드라이브/workspace'\n",
    "\n",
    "# get directory tree\n",
    "def get_dir_tree(dir):\n",
    "    tree = pd.DataFrame(columns=[\"name\", \"path\", \"depth\", \"files\"])\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        name = os.path.basename(root)\n",
    "        this = root.replace(dir, \"\")\n",
    "        depth = int(this.count(os.sep))\n",
    "        count = len(files)\n",
    "        # 숨김 폴더거나, 그 자식 노드일 경우 스킵\n",
    "        if any(f.startswith(\".\") for f in this.split(os.sep)): \n",
    "            print(\"skip:\", this)\n",
    "            continue\n",
    "        tree.loc[len(tree)] = [name, this, depth, count]\n",
    "    return tree\n",
    "\n",
    "\n",
    "def get_dir_index(dir):\n",
    "    index = pd.DataFrame(columns=[\"name\", \"path\", \"is_dir\"])\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        path = root.replace(dir, \"\")\n",
    "        name = os.path.basename(path)\n",
    "        # 숨김 폴더거나, 그 자식 노드일 경우 스킵\n",
    "        if any(f.startswith(\".\") for f in path.split(os.sep)): \n",
    "            print(\"skip:\", path)\n",
    "            continue\n",
    "        index.loc[len(index), :] = [name, path, True]\n",
    "        for f in files:\n",
    "            if f.startswith(\".\"): continue\n",
    "            name = f\n",
    "            path_f = os.sep.join([path, f])\n",
    "            index.loc[len(index), :] = [name, path_f, False]\n",
    "    return index\n",
    "\n",
    "\n",
    "def visualize_tree(tree):\n",
    "    tree = get_dir_tree(sample_dir)\n",
    "    height = len(tree)\n",
    "    width = tree.depth.max() + 2\n",
    "    df = pd.DataFrame(np.full((height, width), \"ｌ\"))\n",
    "    for row in tree.itertuples():\n",
    "        df.loc[row.Index, row.depth] = row.name\n",
    "        df.loc[row.Index, row.depth + 1] = f\"files : {row.count}\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa07125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cik.csv\n",
    "a = pd.read_csv('data/cik.csv')\n",
    "# prettier\n",
    "a.drop(a.columns[0], axis=1, inplace=True)\n",
    "# limit exchange to NYSE or NASDAQ\n",
    "# due to duplicated cik are common in OTC, we need to limit exchange first\n",
    "a.drop(a.index[(a['exchange'] != 'NYSE') & (\n",
    "    a['exchange'] != 'Nasdaq')], inplace=True)\n",
    "# drop all duplicates\n",
    "a.drop_duplicates(subset='cik', keep='first', inplace=True)\n",
    "a.drop_duplicates(subset='name', keep='first', inplace=True)\n",
    "a.drop_duplicates(subset='ticker', keep='first', inplace=True)\n",
    "# column cik to index\n",
    "a.set_index('cik', inplace=True)\n",
    "ticker = a\n",
    "# add col 'ticker', 'exchange' to summaries\n",
    "\n",
    "\n",
    "def findticker(cik):\n",
    "    try:\n",
    "        result = ticker.at[cik, 'ticker']\n",
    "    except:\n",
    "        return\n",
    "    return result\n",
    "\n",
    "\n",
    "def findexchange(cik):\n",
    "    try:\n",
    "        result = ticker.at[cik, 'exchange']\n",
    "    except:\n",
    "        return\n",
    "    return result\n",
    "\n",
    "\n",
    "summaries['TICKER'] = summaries['CIK'].map(findticker)\n",
    "summaries['EXCHANGE'] = summaries['CIK'].map(findexchange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d97a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path_from_date(filing_date):\n",
    "    filing_date = str(filing_date)\n",
    "    year = filing_date[:4]\n",
    "    # month to quarter\n",
    "    month = int(filing_date[4:6])\n",
    "    quarter = (month-1) // 3 + 1\n",
    "    quarter = 'QTR' + str(quarter)\n",
    "    path = os.path.join(PATH, year, quarter)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "23c73414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrqwr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wrqwr'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class what:\n",
    "  \n",
    "  def __init__(self, what):\n",
    "    self.dd = self.what()\n",
    "    self.ee = None\n",
    "    self.eee()\n",
    "\n",
    "  def what(self):\n",
    "    return \"wrqwr\"\n",
    "\n",
    "  def print(self):\n",
    "    print(self.dd)\n",
    "    return\n",
    "\n",
    "  def eee(self):\n",
    "    self.ee = self.dd\n",
    "    return\n",
    "\n",
    "w = what(\"wrqwr\")\n",
    "w.print()\n",
    "w.ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7aaf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class spider:\n",
    "    # import modules\n",
    "    import os\n",
    "    import datetime as dt\n",
    "    from pathlib import Path\n",
    "    from dateutil.parser import parse\n",
    "\n",
    "    import numpy as np\n",
    "    from pickle import dump  # or using hdf5.fixed\n",
    "    from numexpr import evaluate as ne_eval\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.dir = Path(data_path)\n",
    "        self.summary = pd.read_pickle(\n",
    "            self.dir / 'summaries.csv') if (self.dir / 'summaries.csv').exists() else None\n",
    "        self.tree = pd.read_pickle(\n",
    "            self.dir / 'tree.csv') if (self.dir / 'tree.csv').exists() else None\n",
    "        self.index = pd.read_pickle(\n",
    "            self.dir / 'index.csv') if (self.dir / 'index.csv').exists() else None\n",
    "        self.columns = {\n",
    "            \"cik\": self.summary.CIK.values,\n",
    "            \"date\": self.summary.FILING_DATE.values,\n",
    "            \"name\": self.summary.CoName.values,\n",
    "            \"acc\": self.summary.ACC_NUM.values,\n",
    "            \"form\": self.summary.FORM_TYPE.values,\n",
    "            \"symbol\": self.summary.TICKER.values,\n",
    "            \"exchange\": self.summary.EXCHANGE.values\n",
    "        }\n",
    "        self.__set_data()\n",
    "\n",
    "    def __set_data(self):\n",
    "        if not self.summary:\n",
    "            self.summary = pd.read_csv(self.dir / 'data' / 'summaries.csv')\n",
    "        if not self.index:\n",
    "            self.__get_dir_index()\n",
    "            self.__get_dir_tree()\n",
    "        return\n",
    "\n",
    "    def search(self, *keywords):\n",
    "        if not keywords:\n",
    "            return os.listdir(self.dir)\n",
    "        if len(keywords) > 1:\n",
    "            return\n",
    "        # search by keyword\n",
    "        key, modifier = self._search_preprocess(str(keywords[0]))\n",
    "        assert modifier or key, \"input your keyword\"\n",
    "        matrix = []\n",
    "        # 조심해야함\n",
    "        if modifier:\n",
    "            matrix.append([self._get_from_modifier(mod, value)\n",
    "                          for mod, value in modifier.items()])\n",
    "        if key:\n",
    "            matrix.append([self._get_from_key(key, value)\n",
    "                          for key, value in key.items()])\n",
    "        idx = np.multiply.reduce(matrix)\n",
    "        # to boolean array\n",
    "        idx = np.array([True if i else False for i in idx[0]])\n",
    "        # result = summaries[idx][['FILING_DATE', 'ACC_NUM']]\n",
    "        # result.set_index('ACC_NUM', inplace=True)\n",
    "        return self.summary[idx]\n",
    "\n",
    "    def make_df_from_path(self, paths):\n",
    "        # make dataframe that has colums of date, type, acc, text\n",
    "        df = pd.DataFrame(columns=[\"date\", \"type\", \"acc\", \"text\"])\n",
    "        for path in paths:\n",
    "            file = os.path.basename(path)\n",
    "            date = file.split(\"_\")[0]\n",
    "            type = file.split(\"_\")[1]\n",
    "            acc = file.split(\"_\")[5].replace(\".txt\", \"\")\n",
    "            text = open(path, \"r\").read()\n",
    "            # append to df\n",
    "            df = df.append(pd.DataFrame([[date, type, acc, text]], columns=[\n",
    "                           \"date\", \"type\", \"acc\", \"text\"]))\n",
    "        return df\n",
    "        # input: list of path\n",
    "        # get filename from path\n",
    "        # output:\n",
    "\n",
    "    def show_tree(self):\n",
    "        result = ''\n",
    "        for row in self.tree.itertuples():\n",
    "            result.append('\\t'*row.depth + row.name +\n",
    "                          f\"\\tfiles: {row.count}\\n\")\n",
    "        return result\n",
    "\n",
    "    def _search_preprocess(self, keyword):\n",
    "        # params : string for search\n",
    "        # return : list of keywords + tags\n",
    "        key_tags = ['cik', 'date', 'name', 'symbol', 'acc', 'form']\n",
    "        modifier_tags = ['after', 'before', 'year', 'qtr']\n",
    "        keyword_list = keyword.split(' ')\n",
    "        # unknown 인식 및 처리 과정 필요\n",
    "        unknown = list(filter(lambda x: ':' not in x, keyword_list))\n",
    "        tag = list(filter(lambda x: ':' in x, keyword_list))\n",
    "        tag = dict(tuple(x.split(':')) for x in tag) if tag else {}\n",
    "        key = {k: v for k, v in tag.items() if k in key_tags}\n",
    "        modifier = {k: v for k, v in tag.items() if k in modifier_tags}\n",
    "        # 현재 dateparser 적용 안되는 오류\n",
    "        for k, val in modifier.items():\n",
    "            val = self._date_parser(val)\n",
    "        modifier = {k: v for k, v in modifier.items() if v}\n",
    "        return key, modifier\n",
    "\n",
    "    def _date_parser(self, date):\n",
    "        if len(date) == 4:\n",
    "            if date.startswith(('19', '20')):\n",
    "                # 연도만 입력된 경우\n",
    "                return date+'0101'\n",
    "            if date <= '1231':\n",
    "                # 월일만 입력된 경우, 분기조건 수정 필요\n",
    "                year = str(dt.now().year)\n",
    "                return year + date\n",
    "        # try 내에서 return 사용 가능?\n",
    "        try:\n",
    "            result = parse(date).strftime('%Y%m%d')\n",
    "        except:\n",
    "            return None\n",
    "        return result\n",
    "\n",
    "    def __get_dir_tree(self):\n",
    "        tree = pd.DataFrame(columns=[\"name\", \"path\", \"depth\", \"files\"])\n",
    "        for root, dirs, files in os.walk(self.dir):\n",
    "            name = os.path.basename(root)\n",
    "            this = root.replace(self.dir, \"\")\n",
    "            depth = int(this.count(os.sep))\n",
    "            count = len(files)\n",
    "            # 숨김 폴더거나, 그 자식 노드일 경우 스킵\n",
    "            if any(f.startswith(\".\") for f in this.split(os.sep)):\n",
    "                print(\"skip:\", this)\n",
    "                continue\n",
    "            tree.loc[len(tree)] = [name, this, depth, count]\n",
    "        return tree\n",
    "\n",
    "    def __get_dir_index(dir):\n",
    "        index = pd.DataFrame(columns=[\"name\", \"path\", \"is_dir\"])\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            path = root.replace(dir, \"\")\n",
    "            name = os.path.basename(path)\n",
    "            # 숨김 폴더거나, 그 자식 노드일 경우 스킵\n",
    "            if any(f.startswith(\".\") for f in path.split(os.sep)):\n",
    "                print(\"skip:\", path)\n",
    "                continue\n",
    "            index.loc[len(index), :] = [name, path, True]\n",
    "            for f in files:\n",
    "                if f.startswith(\".\"):\n",
    "                    continue\n",
    "                name = f\n",
    "                path_f = os.sep.join([path, f])\n",
    "                index.loc[len(index), :] = [name, path_f, False]\n",
    "        return index\n",
    "\n",
    "    def _get_depth(self, path):\n",
    "        for root, dir, file in os.walk(path):\n",
    "            if file and not dir:\n",
    "                self.depth = root.count(os.sep)-path.count(os.sep)+1\n",
    "        return \"ERROR\"\n",
    "\n",
    "    def _get_subdir(self, path):\n",
    "        \"\"\"search for subdir in path\n",
    "        return list of subdir\n",
    "        every iteration, check next(os.walk(subdir))[1]\n",
    "        if empty continue to next iteration\"\"\"\n",
    "        return \"ERROR\"\n",
    "\n",
    "    def _get_from_key(self, key, value):\n",
    "        col = self.columns[key]\n",
    "        idx = ne_eval(f'(col == {value})')\n",
    "        return idx\n",
    "\n",
    "    def _get_from_modifier(self, modifier, value):\n",
    "        date = self.columns[\"date\"]\n",
    "        value = str(value)\n",
    "        after = \"10000000\"\n",
    "        before = \"99999999\"\n",
    "        if modifier == 'after':\n",
    "            after = value\n",
    "        elif modifier == 'before':\n",
    "            before = value\n",
    "        elif modifier == 'year':\n",
    "            after = value[:4] + '0101'\n",
    "            before = value[:4] + '1231'\n",
    "        elif modifier == 'qtr':\n",
    "            after = value\n",
    "            before = value[:4] + str(int(value[4:6])+3) + value[6:]\n",
    "        idx = ne_eval(f'({int(after)} < date) & (date < {int(before)})')\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696b95e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'CIK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/GoogleDrive/내 드라이브/workspace/jpynb/edgar/File.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m date \u001b[39m=\u001b[39m spider(PATH)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a \u001b[39m=\u001b[39m date\u001b[39m.\u001b[39msearch(\u001b[39m'\u001b[39m\u001b[39mcik:861439\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m np\u001b[39m.\u001b[39mcount_nonzero(a)\n",
      "\u001b[1;32m/Volumes/GoogleDrive/내 드라이브/workspace/jpynb/edgar/File.ipynb 셀 9\u001b[0m in \u001b[0;36mspider.__init__\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtree.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtree.csv\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mindex.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mindex.csv\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m {\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcik\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msummary\u001b[39m.\u001b[39;49mCIK\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mFILING_DATE\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mCoName\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39macc\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mACC_NUM\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mform\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mFORM_TYPE\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msymbol\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mTICKER\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mexchange\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mEXCHANGE\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/GoogleDrive/%EB%82%B4%20%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C/workspace/jpynb/edgar/File.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_data()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'CIK'"
     ]
    }
   ],
   "source": [
    "date = spider(PATH)\n",
    "a = date.search('cik:861439')\n",
    "np.count_nonzero(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13bb3b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094786\n",
      "42540 57459\n",
      "UNITED REFINING CO                            680\n",
      "ENTERGY CORP /DE/                             543\n",
      "708 GYM LLC                                   543\n",
      "SOUTHERN CO                                   468\n",
      "OUTSOURCING SOLUTIONS INC                     461\n",
      "                                             ... \n",
      "Volkswagen Auto Loan Enhanced Trust 2011-1      2\n",
      "VOLKSWAGEN AUTO LEASE TRUST 2012-A              2\n",
      "FLEET CREDIT CARD MASTER TRUST II               2\n",
      "SLC Student Loan Trust 2004-1                   2\n",
      "BINGO COM INC                                   2\n",
      "Name: CoName, Length: 1672, dtype: int64\n",
      "1367306    420\n",
      "1383094    244\n",
      "1347185    163\n",
      "1477336    143\n",
      "1002761    123\n",
      "          ... \n",
      "1069892      1\n",
      "1069891      1\n",
      "1069890      1\n",
      "1069604      1\n",
      "1049299      1\n",
      "Name: CIK, Length: 3009, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0              LOUISIANA LAND & EXPLORATION CO\n",
       "1          MINNESOTA MINING & MANUFACTURING CO\n",
       "2              LOUISIANA LAND & EXPLORATION CO\n",
       "3              LOUISIANA LAND & EXPLORATION CO\n",
       "4                    BETHLEHEM STEEL CORP /DE/\n",
       "                          ...                 \n",
       "1140481                    Umatrin Holding Ltd\n",
       "1140482           QMIS TBS Capital Group Corp.\n",
       "1140483                          Linktory Inc.\n",
       "1140484                           Energem Corp\n",
       "1140485                            NEOGEN CORP\n",
       "Name: CoName, Length: 1140486, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # summaries = summaries.csv['']\n",
    "# # innocent = ACC_NUM이 중복되지 않은 리스트\n",
    "# innocent = summaries.drop_duplicates(subset=['ACC_NUM'], keep=False)\n",
    "# print(len(innocent))\n",
    "# inn_cik =  innocent['CIK'].value_counts()\n",
    "# inn_co =  innocent['CoName'].value_counts()\n",
    "# inn_co\n",
    "# print(len(inn_cik), len(inn_co))\n",
    "# # get duplicated acc num\n",
    "# duplicated = summaries[summaries['ACC_NUM'].duplicated(keep=False)]\n",
    "# counts = duplicated['ACC_NUM'].value_counts()\n",
    "# coname = duplicated['CoName'].value_counts()\n",
    "# cik = duplicated['CIK'].value_counts()\n",
    "# acc = counts.index\n",
    "# print(coname)\n",
    "# print(cik)\n",
    "# coname\n",
    "# summaries['CoName']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('inbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0b953d38d32bee56bb9b5ad28b40e8629c17cf4086415c01cce2c83f27cf769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
